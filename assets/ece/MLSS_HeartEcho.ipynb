{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random \n",
    "import copy\n",
    "from PIL import Image\n",
    "import itertools\n",
    "from torchvision import models, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score, average_precision_score, balanced_accuracy_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data paths and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "root_dir =  ## TO UPDATE ACCORDINGLY\n",
    "annot_dir = root_dir + 'FileList.csv'\n",
    "tracings_dir = root_dir + 'VolumeTracings.csv'\n",
    "\n",
    "# parameters\n",
    "batch_size = \n",
    "num_workers = \n",
    "num_epochs = \n",
    "seed = 42\n",
    "CLASS_NAMES = ['Heart Failure', 'No Finding'] # (<ef_cutoff, >ef_cutoff)\n",
    "ef_cutoff = 50\n",
    "plotYorN = False\n",
    "\n",
    "# model\n",
    "model_selection = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read csv\n",
    "df = pd.read_csv(annot_dir)\n",
    "\n",
    "# histogram\n",
    "plt.hist(df['EF'],100, label='original')\n",
    "plt.ylim([0,600])\n",
    "\n",
    "# data cleaning \n",
    "# remove samples that do not have standard frame height (112)\n",
    "# remove samples that has less than standard number frames (112)\n",
    "# remove samples with ef_range\n",
    "df = df.drop(df[df['FrameHeight']!= 112].index)\n",
    "df = df.drop(df[df['NumberOfFrames'] < 112].index)\n",
    "df = df.drop(df[(df['EF'] >= (ef_cutoff-5)) & (df['EF'] <= (ef_cutoff+10))].index)\n",
    "df['Label'] = df['EF']\n",
    "df = df.drop(columns=['EF','ESV','EDV','FrameHeight','FrameWidth','FPS'])\n",
    "df['EDES_1'] = 0\n",
    "df['EDES_2'] = 0\n",
    "print('Number of videos total: ', len(df))\n",
    "\n",
    "# data cleaning\n",
    "print('Number of videos with HF: ', sum(df['Label'] < ef_cutoff))\n",
    "\n",
    "# read csv\n",
    "ef_frames = pd.read_csv(tracings_dir)\n",
    "ef_frames = ef_frames.drop_duplicates(subset=['FileName','Frame'],ignore_index = True)\n",
    "ef_frames = ef_frames.sort_values(by=['FileName'])\n",
    "\n",
    "# data cleaning\n",
    "ef_frames = ef_frames.drop(columns=['X1','Y1','X2','Y2'])\n",
    "ef_frames = ef_frames.drop_duplicates(ignore_index=True)\n",
    "ef_frames['FileName']= ef_frames['FileName'].str.split('.avi').str.get(0)\n",
    "\n",
    "# iterate over patients\n",
    "ids = sorted(df.index.tolist())\n",
    "for i in ids:\n",
    "    curr_frames = list(ef_frames[ef_frames['FileName'].str.contains(df['FileName'][i])]['Frame'])\n",
    "    df['EDES_1'][i] = curr_frames[0]\n",
    "    df['EDES_2'][i] = curr_frames[1]\n",
    "# print(df)\n",
    "    \n",
    "# histogram\n",
    "plt.hist(df['Label'],100, label='reduced')\n",
    "plt.ylim([0,600])\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('EF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Val, Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient id split\n",
    "patient_id = sorted(list(set(df['FileName'])))\n",
    "\n",
    "# TRAIN\n",
    "train_idx = df[df['Split']=='TRAIN']['FileName']\n",
    "print('Number of patients in the training set: ', len(train_idx))\n",
    "\n",
    "# get the train dataframe and sample\n",
    "df_train = df[df['FileName'].isin(train_idx)]  \n",
    "train_idx = list(train_idx)\n",
    "train_label = list(df_train['Label']) \n",
    "train_frame_1 = list(df_train['EDES_1']) \n",
    "train_frame_2 = list(df_train['EDES_2']) \n",
    "\n",
    "# VAL\n",
    "\n",
    "# TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    # back to random seeds\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # for cuda\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    \n",
    "def loadvideo(filename: str) -> np.ndarray:\n",
    "    \"\"\"Loads a video from a file.\n",
    "    Args:\n",
    "        filename (str): filename of video\n",
    "    Returns:\n",
    "        A np.ndarray with dimensions (channels=3, frames, height, width). The\n",
    "        values will be uint8's ranging from 0 to 255.\n",
    "    Raises:\n",
    "        FileNotFoundError: Could not find `filename`\n",
    "        ValueError: An error occurred while reading the video\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(filename):\n",
    "        raise FileNotFoundError(filename)\n",
    "    capture = cv2.VideoCapture(filename)\n",
    "\n",
    "    frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    v = np.zeros((frame_count, frame_height, frame_width, 3), np.uint8)\n",
    "\n",
    "    for count in range(frame_count):\n",
    "        ret, frame = capture.read()\n",
    "        if not ret:\n",
    "            raise ValueError(\"Failed to load frame #{} of {}.\".format(count, filename))\n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        v[count, :, :] = frame\n",
    "\n",
    "    v = v.transpose((3, 0, 1, 2))\n",
    "    \n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return v     \n",
    "        \n",
    "class DatasetGenerator(Dataset):\n",
    "    \n",
    "    def __init__ (self, img_list, label_list, frame_list_1, frame_list_2, transform):\n",
    "    \n",
    "        self.transform = transform\n",
    "        self.frame_list_1 = frame_list_1\n",
    "        self.frame_list_2 = frame_list_2\n",
    "        self.img_list = img_list\n",
    "        self.listImageLabels = label_list\n",
    "        \n",
    "        imgLabel_cnt = np.zeros(len(CLASS_NAMES))\n",
    "        \n",
    "        # iterate over imgs\n",
    "        for i in range(len(img_list)):\n",
    "            imgLabel = label_list[i]\n",
    "            if imgLabel > ef_cutoff:\n",
    "                imgLabel_cnt = imgLabel_cnt + [0,1]\n",
    "            else:\n",
    "                imgLabel_cnt = imgLabel_cnt + [1,0] \n",
    "        print(imgLabel_cnt)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # video path\n",
    "        curr_file = root_dir + 'Videos/' + self.img_list[index] + '.avi'\n",
    "        \n",
    "        # load and pad video\n",
    "        pad = 6\n",
    "        video = loadvideo(curr_file)\n",
    "        c, l, h, w = video.shape\n",
    "        temp = np.zeros((c, l, h + 2 * pad, w + 2 * pad), dtype=video.dtype)\n",
    "        temp[:, :, pad:-pad, pad:-pad] = video  # pylint: disable=E1130\n",
    "        i, j = np.random.randint(0, 2 * pad, 2)\n",
    "        video = temp[:, :, i:(i + h), j:(j + w)]\n",
    "        \n",
    "        # get the frame\n",
    "        imageData = np.zeros((h,w,c))\n",
    "        tmp = video[:,self.frame_list_1[index],:,:].transpose(1,2,0)\n",
    "        imageData[:,:,0] = tmp[:,:,0]\n",
    "        tmp = video[:,round((self.frame_list_1[index]+self.frame_list_2[index])/2),:,:].transpose(1,2,0)\n",
    "        imageData[:,:,1] = tmp[:,:,0]\n",
    "        tmp = video[:,self.frame_list_2[index],:,:].transpose(1,2,0)\n",
    "        imageData[:,:,2] = tmp[:,:,0]\n",
    "        if plotYorN:\n",
    "            plt.subplot(1,3,1)\n",
    "            plt.imshow(imageData[:,:,0])  \n",
    "            plt.subplot(1,3,2)\n",
    "            plt.imshow(imageData[:,:,1])  \n",
    "            plt.subplot(1,3,3)\n",
    "            plt.imshow(imageData[:,:,2])  \n",
    "            plt.pause(0.01)\n",
    "        imageData = Image.fromarray(imageData.astype('uint8'),'RGB')\n",
    "        if self.transform != None: imageData = self.transform(imageData)    \n",
    "        image_label = self.listImageLabels[index]\n",
    "        \n",
    "        return imageData, image_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.listImageLabels)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 4))\n",
    "index = 15\n",
    "print(train_idx[index])\n",
    "curr_file = root_dir + 'Videos/' + train_idx[index] + '.avi'\n",
    "frames = [train_frame_1[index],train_frame_2[index]]\n",
    "print(frames)\n",
    "        \n",
    "# load and pad video\n",
    "pad = 6\n",
    "video = loadvideo(curr_file)\n",
    "c, l, h, w = video.shape\n",
    "temp = np.zeros((c, l, h + 2 * pad, w + 2 * pad), dtype=video.dtype)\n",
    "temp[:, :, pad:-pad, pad:-pad] = video  # pylint: disable=E1130\n",
    "i, j = np.random.randint(0, 2 * pad, 2)\n",
    "video = temp[:, :, i:(i + h), j:(j + w)]\n",
    "print(len(range(frames[0]-20,frames[1]+20,4)))\n",
    "        \n",
    "# get the frame\n",
    "cnt = 1\n",
    "for i in range(frames[0]-20,frames[1]+20,4):\n",
    "    tmp = video[:,i,:,:].transpose(1,2,0)\n",
    "    plt.subplot(1, len(range(frames[0]-20,frames[1]+20,4)), cnt)\n",
    "    plt.imshow(tmp)  \n",
    "    plt.axis('off')\n",
    "    plt.title(str(i))\n",
    "    cnt = cnt + 1\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.05, \n",
    "                    hspace=0.05)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# gpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # \n",
    "print('Using {} device'.format(device))\n",
    "set_seeds(seed)\n",
    "\n",
    "# transform functions\n",
    "transCrop = \n",
    "transResize = \n",
    "transformList = []\n",
    "transformList.append(transforms.Resize(size=transResize))\n",
    "transformList.append(transforms.ToTensor())\n",
    "train_transform=transforms.Compose(transformList)\n",
    "\n",
    "transformList = []\n",
    "transformList.append(transforms.Resize(transResize))\n",
    "transformList.append(transforms.ToTensor())\n",
    "test_transform=transforms.Compose(transformList)\n",
    "\n",
    "# datasets\n",
    "image_datasets = {'train': DatasetGenerator(img_list = train_idx, \n",
    "                                              label_list = train_label, \n",
    "                                              frame_list_1 = train_frame_1,\n",
    "                                              frame_list_2 = train_frame_2,\n",
    "                                              transform=train_transform),\n",
    "                      'val': DatasetGenerator(img_list = val_idx, \n",
    "                                              label_list = val_label, \n",
    "                                              frame_list_1 = val_frame_1,\n",
    "                                              frame_list_2 = val_frame_2,\n",
    "                                              transform=test_transform), \n",
    "                      'test': DatasetGenerator(img_list = test_idx, \n",
    "                                              label_list = test_label, \n",
    "                                              frame_list_1 = test_frame_1,\n",
    "                                              frame_list_2 = test_frame_2,\n",
    "                                              transform=test_transform)}\n",
    "\n",
    "# dataset sizes\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "print(dataset_sizes)\n",
    "\n",
    "# dataloader\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True, \n",
    "                                              num_workers=num_workers)\n",
    "               for x in ['train', 'val', 'test']}\n",
    "\n",
    "id = 50\n",
    "print(train_idx[id], train_label[id])\n",
    "plt.imshow(image_datasets['train'][id][0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_metrics(preds_vec, labels_vec, class_names):\n",
    "    # TODO\n",
    "    \n",
    "    return roc_auc, average_precision, balanced_acc, f1_acc\n",
    "    \n",
    "\n",
    "# training the model\n",
    "def train_model(dataloaders, model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    \n",
    "    # best model parameters\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = np.Inf\n",
    "    best_acc = 0\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    # iterate over epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        if epoch % 5 == 0:\n",
    "            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "            print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            # set model to training mode\n",
    "            if phase == 'train':\n",
    "                model.train()  \n",
    "                \n",
    "            # set model to evaluate mode    \n",
    "            else:\n",
    "                model.eval()   \n",
    "\n",
    "            # TODO\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                \n",
    "            # get some metrics\n",
    "            # TODO\n",
    "            \n",
    "            # print\n",
    "            print('{} Loss: {:.4f} MSE: {:.4f} MAE {:.4f} AUROC: {:.4f} Balanced Acc. {:.4f} Avg. Precision: {:.4f}'.format(\n",
    "                phase, epoch_loss, mse, mae, auroc, balanced_acc, avg_precision))\n",
    "            \n",
    "            # save the accuracy and loss\n",
    "            if phase == 'train':\n",
    "                train_acc.append(epoch_acc)\n",
    "                train_loss.append(epoch_loss)\n",
    "            elif phase == 'val':\n",
    "                val_acc.append(epoch_acc)\n",
    "                val_loss.append(epoch_loss)\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_acc = epoch_acc\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # time    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Loss: {:4f}'.format(best_loss))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, train_acc, train_loss, val_acc, val_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# back to random seeds\n",
    "set_seeds(seed)\n",
    "\n",
    "# model\n",
    "if model_selection == 'vgg16':\n",
    "    model_ft = models.vgg16(pretrained=True)\n",
    "    num_ftrs = model_ft.classifier[6].in_features\n",
    "    model_ft.classifier[6] = nn.Linear(num_ftrs, 1)\n",
    "    model_ft.classifier[6].bias.data[0] = 55.6\n",
    "elif model_selection == 'resnet18':  \n",
    "    # TODO\n",
    "    \n",
    "elif model_selection == 'resnet34':\n",
    "    # TODO\n",
    "    \n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# loss function\n",
    "criterion = \n",
    "  \n",
    "# observe that all parameters are being optimized\n",
    "optimizer_ft = \n",
    "scheduler_ft = \n",
    "\n",
    "# train model\n",
    "model_ft, train_acc, train_loss, val_acc, val_loss = train_model(dataloaders,\n",
    "                                                                 model_ft, \n",
    "                                                                 criterion, \n",
    "                                                                 optimizer_ft, \n",
    "                                                                 scheduler_ft,\n",
    "                                                                 num_epochs=num_epochs)\n",
    "\n",
    "# plot\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(0, num_epochs), train_acc, label = 'Train')\n",
    "plt.plot(range(0, num_epochs), val_acc, label = 'Val')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(0, num_epochs), train_loss, label = 'Train')\n",
    "plt.plot(range(0, num_epochs), val_loss, label = 'Val')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_vec = np.zeros(dataset_sizes['test'])\n",
    "labels_vec = np.zeros(dataset_sizes['test'])\n",
    "probs_mat = np.zeros((dataset_sizes['test'],1))\n",
    "cnt = 0\n",
    "\n",
    "# iterate over data\n",
    "for inputs, labels in dataloaders['test']:\n",
    "                \n",
    "    # send inputs and labels to device\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device).to(torch.float)\n",
    "    outputs = model_ft(inputs)\n",
    "    probs_mat[cnt*batch_size:(cnt+1)*batch_size,:] = outputs.cpu().detach().numpy()\n",
    "    labels_vec[cnt*batch_size:(cnt+1)*batch_size] = labels.cpu().detach().numpy()\n",
    "    cnt = cnt + 1\n",
    "                \n",
    "# get the metrics\n",
    "mse = mean_squared_error(labels_vec, probs_mat, squared=False)\n",
    "mae = mean_absolute_error(labels_vec, probs_mat)\n",
    "auroc, avg_precision, balanced_acc, _ = compute_accuracy_metrics(probs_mat,labels_vec>ef_cutoff,CLASS_NAMES)  \n",
    "            \n",
    "# print\n",
    "print('{} MSE: {:.4f} MAE {:.4f} AUROC: {:.4f} Balanced Acc. {:.4f} Avg. Precision: {:.4f}'.format(\n",
    "        'Test set: ', mse, mae, auroc, balanced_acc, avg_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EF plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [3, 3]\n",
    "plt.plot(labels_vec,probs_mat,'.k')\n",
    "plt.xlim([0,85])\n",
    "plt.ylim([0,85])\n",
    "plt.plot(np.linspace(0, 85, 10),np.linspace(0, 85, 10),'b')\n",
    "plt.xlabel('Actual EF')\n",
    "plt.ylabel('Predicted EF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "fig = plt.figure(figsize=(3, 3))\n",
    "plt.plot([0, 1], [0, 1], linewidth=1, color=\"k\", linestyle=\"--\")\n",
    "for thresh in [ef_cutoff]: # [35, 40, 45, 50]:\n",
    "    fpr, tpr, _ = sklearn.metrics.roc_curve(labels_vec>thresh, probs_mat)\n",
    "    print(sklearn.metrics.roc_auc_score(labels_vec>thresh, probs_mat))\n",
    "    plt.plot(fpr, tpr,'k')\n",
    "\n",
    "    plt.axis([-0.01, 1.01, -0.01, 1.01])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot area\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "\n",
    "# get the images from the dataloader\n",
    "inputs, labels = next(iter(dataloaders['test']))\n",
    "rgb_img = inputs.numpy()\n",
    "labels = np.round(labels.numpy(),2)\n",
    "inputs = inputs.to(device)\n",
    "outputs = np.round(model_ft(inputs).cpu().detach().numpy(),2)\n",
    "\n",
    "# visualization\n",
    "idx = 16\n",
    "for i in range(idx):\n",
    "    plt.subplot(round(idx/4), 4, i+1)\n",
    "    plt.imshow(rgb_img[i,:,:].transpose(1,2,0))\n",
    "    plt.title([labels[i],outputs[i][0]])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
