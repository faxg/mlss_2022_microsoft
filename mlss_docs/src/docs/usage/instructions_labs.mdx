---
title: Setup instructions for different labs
description: How to setup Azure ML for the labs, access the data etc.
disableTableOfContents: false
---

**General note**:
If you intend to use the same compute instance for multiple lectures, make sure to
isolate dependiencies by installing them in separate (conda) environments.

Also note, that currently **GPU based** computes are unfortunatly not available for the free credits.
You will probably get an error when trying to provision a GPU-based compute instance. If that's a big issue for the labs, let us know.
Currently, the easiest workaround is to just use a CPU-based compute instance instead.

## Intro video:

Video explaining a few things about how to setup Azure ML for the labs, and upload and access data:
https://vimeo.com/737253841/446ce14fac

<div style="padding:66.67% 0 0 0;position:relative;">
  <iframe
    src="https://player.vimeo.com/video/737253841?h=446ce14fac&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479"
    frameborder="0"
    allow="autoplay; fullscreen; picture-in-picture"
    allowfullscreen
    style="position:absolute;top:0;left:0;width:100%;height:100%;"
    title="Azure ML - Prepare for Lectures"
  ></iframe>
</div>
<script src="https://player.vimeo.com/api/player.js"></script>

## Sunday Lecture: Valeria De Luca

**Lecturer**: [Valeria De Luca](https://www.linkedin.com/in/valeria-de-luca-83b49673/), Novartis

**Description**:

- Dataset: https://zenodo.org/record/4266157#.YuagXexBzc9
  I have one additional table to provide (TBC), which is not included there, nor posted online.
- This will be shared with the students

- **Setup**: I will not provide a template notebook, but I have a list of scientific questions to address, which will be split among teams.
  Depending on the questions, there might be different libraries that a team would need / like to use
- **Requirements**: not much, the dataset is quite small and I do not expect large computational needs.
- **Additional data**: some additional data from the public domain could be of interest for the team (not necessary but interesting), e.g. weather data.
  can they eventually upload data during the tutorial? Or should I provide these upfront as well?

---

## Monday Lecture: Clinical Trials

**Lecturer**: [Jonas Dorn](https://www.linkedin.com/in/jonas-dorn-6b371933/), Roche

**Description**:

For my tutorial,
I would like the students to take a look at actigraphy data
(https://mueller-et-al-2019.s3.amazonaws.com/index.html - folder interventional-clinical-trial;
the data is public and can be downloaded to Azure ahead of time),
and, looking at either the raw data or the steps data assess whether the data are consistent enough (within patient)
and or similar enough (across patients) so that we can average their overall daily activity patterns.

The participants will need at least

```bash
numpy
scipy
h5py (to read hdf5 data)
```

... plus visualization (my sample notebook uses plotly) and their favorite ML library if they think it will help.

---

## Tuesday Lecture 1: Engineering Toolbox

** Lecturer**: [Alexander Marx](https://www.linkedin.com/in/alexander-marx-279013188/), ETH Zurich AI

**Description**:

This lab requires some **R** libraries and **graphwiz** and the **Causal Discovery Toolbox** installed on your compute.

- [requirements.txt](/assets/alexander/requirements.txt)
- [check-installation.ipynb](/assets/alexander/check-installation.ipynb)

Here's one way that should work in your Azure ML Studio (you need to have a Compute instance created first):

1. Got to `Notebooks > Open Terminal`
2. Run these :

```bash
  sudo apt install -y graphviz
  pip install cdt causal-learn pydot
```

3. You also need to instal **R** and some packages, see instructions here (under **Additional : R and R libraries**):
   https://github.com/FenTechSolutions/CausalDiscoveryToolbox

---

## Tuesday Lecture 2: Medical Image processing

**Lecturer**: [Ece Ã–zkan Elsen](https://www.linkedin.com/in/ece-%C3%B6zkan-elsen-452716180/), ETH Zurich

**Description**:

I will be using EchoNet-Dynamic dataset:
https://echonet.github.io/dynamic/

Every participant needs to have/sign an agreement as well to access the data.
I prepared an initial Jupyter notebook which runs a short code with everything they need (data and libraries).

- [Libraries](/assets/ece/libraries_list_heartEcho_Ece.txt)
- [Getting ready Notebook](/assets/ece/GettingReady.ipynb)

For sharing the large dataset, there are multiple options.

- The lecturer could upload the data to a central data store and share access to students.

Or

- You can upload the data to your own Azure ML datastore (part of your workspace).
- In Azure ML Studio, select **Data** on the left, and "Create" (upload, specify url etc..)

---

## Wednesday Lecture: Time Series and Chest X-ray images

**Lecturer**: [Farah Shamout](https://www.linkedin.com/in/farahshamout/), NYU Abu Dhabi

**Description**:

My multimodal learning tutorial will be based on the publicly available MIMIC-IV and MIMIC-CXR datasets.
This requires the students to first complete IRB training in order to be allowed access.
https://physionet.org/content/mimiciv/2.0/
https://physionet.org/content/mimic-cxr/2.0.0/

The benchmark is MedFuse: https://arxiv.org/abs/2207.07027
https://github.com/nyuad-cai/MedFuse

Instructions for installing the environment for my tutorial are listed on the repo:
https://github.com/nyuad-cai/MedFuse#Environment-setup

```bash
git clone https://github.com/nyuad-cai/MedFuse.git
cd MedFuse
conda env create -f environment.yml
conda activate medfuse
```

---

## Thursday Lecture: Genomic Data

**Lecturer**: [Kathy Chen](https://www.linkedin.com/in/kathy-chen-5a33aa92/), Princeton

**Description**:

I think more or less if I can recommend students create a standalone anaconda environment, e.g.

```
conda create --name selene-py38 python=3.8
conda activate selene-py38
pip install selene-sdk
conda install -c anaconda docopt
```

---
